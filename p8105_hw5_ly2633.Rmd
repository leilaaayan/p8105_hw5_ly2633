---
title: "p8105_hw5_ly2633"
author: "Leila Yan"
date: "2024-11-04"
output: html_document
---
```{r}
# Load libraries
library(tidyverse)
library(ggplot2)
```
# Problem 1


# Problem 2
Question: Conduct a simulation to explore power in a one-sample t-test.
For each dataset, save ðœ‡Ì‚ and the p-value arising from a test of ð»:ðœ‡=0using ð›¼=0.05
Hint: to obtain the estimate and p-value, use broom::tidy to clean the output of t.test.
```{r}
onesample_t_test = function(mu){
  n=30
  sigma = 5
  x=rnorm(n,mean=mu,sd=sigma)
  
  t_test_output = t.test(x,mu=0, conf.level = 0.95)|>
              broom::tidy()
  
  return(t_test_output)
}

onesample_t_test_sim = 
  expand_grid(
    mu = c(0:6),
    iter = 1:5000
  ) %>%
  mutate(
    ttest_output = map(mu, onesample_t_test)
  ) %>%
  unnest(ttest_output)
```

Question: Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of ðœ‡on the x axis. Describe the association between effect size and power.
```{r}
onesample_t_test_sim %>%
  mutate(
    reject = ifelse(p.value < 0.05, 1, 0)
  )%>%
  group_by(mu,reject) %>%
  filter(reject == 1)%>%
  summarise(reject_count =n())%>%
  mutate(power = reject_count/5000)%>%
  ggplot(aes(x=mu, y=power))+
  geom_point()+
  geom_line()+
  labs(x="Mean")
```
Answers:
We see a clear positive association between effect size and power. When the true value of Î¼ is small, the power is low, meaning the test has a lower chance of detecting an effect and rejecting the null hypothesis. As Î¼ increases, power rises as well, approaching 1 for higher values of Î¼. This trend indicates that with larger effect sizes, it becomes easier for the test to identify a difference from the null, leading to a higher probability of rejection. This behavior is expected in hypothesis testing; small effects are more challenging to detect due to their similarity to random noise, resulting in lower power. Conversely, as the effect size grows, the distinction from the null becomes more pronounced, allowing the test to detect the effect with greater accuracy, thus increasing power.


Question: Make a plot showing the average estimate of ðœ‡Ì‚ on the y axis and the true value of ðœ‡on the x axis. Make a second plot (or overlay on the first) the average estimate of ðœ‡Ì‚ only in samples for which the null was rejected on the y axis and the true value of ðœ‡on the x axis. Is the sample average of ðœ‡Ì‚ across tests for which the null is rejected approximately equal to the true value of ðœ‡? Why or why not?
```{r}
onesample_t_test_summary = onesample_t_test_sim %>%
  mutate(
    reject = ifelse(p.value < 0.05, 1, 0)
  ) %>%
  group_by(mu) %>%
  summarise(
    avg_mu_hat_all = mean(estimate),
    avg_mu_hat_rejected = mean(estimate[reject == 1]),
    .groups = 'drop'
  )


ggplot(onesample_t_test_summary, aes(x = mu)) +
  geom_line(aes(y = avg_mu_hat_all, color = "All Samples")) +
  geom_point(aes(y = avg_mu_hat_all, color = "All Samples")) +
  geom_line(aes(y = avg_mu_hat_rejected, color = "Rejected Samples")) +
  geom_point(aes(y = avg_mu_hat_rejected, color = "Rejected Samples")) +
  labs(
    x = "True Mean (Î¼)",
    y = "Average Estimate of Î¼Ì‚",
    title = "Average Estimate of Î¼Ì‚ by True Value of Î¼",
    color = "Sample Group"
  ) +
  theme_minimal()
```
Answer:
The average estimate closely follows the trueðœ‡, indicating an unbiased estimate. However, for samples where the null was rejected, the average estimate of  ðœ‡Ì‚is consistently higher than the trueðœ‡ , particularly at lower values.  Thus, the sample average across tests for which the null is rejected is not approximately equal to the true value of ðœ‡. This is because when focusing only on tests that reject the null hypothesis, we introduce a selection bias that overrepresents larger observed effects, leading to an upward bias in the estimate of ðœ‡.


# Problem 3
Describe the raw data.
```{r}
# load the data
homicide_data = 
  read.csv("homicide-data.csv") %>%
  janitor::clean_names()

```
Answer:


```{r}
# Create a city_state variable (e.g. â€œBaltimore, MDâ€)
homicide_data = homicide_data %>%
  mutate(state = ifelse(city == "Seattle", "WA", state),
         city_state = paste(city, state, sep=", "))

# Summarize within cities to obtain the total number of homicides and the number of unsolved homicides(those for which the disposition is â€œClosed without arrestâ€ or â€œOpen/No arrestâ€).
totnumber_homicides = 
  homicide_data %>%
  group_by(city_state) %>%
  summarise(totnumber_homicide = n())

totnumber_unsolved =
  homicide_data %>%
  group_by(city_state) %>%
  filter(disposition %in% c("Open/No arrest", "Closed without arrest"))|>
  summarise(totnumber_unsolved = n())

# Join the the total number of homicides and the number of unsolved homicides
total_counts = 
  totnumber_homicides %>%
  left_join(totnumber_unsolved)

total_counts
```


For the city of Baltimore, MD, use the prop.test function to estimate the proportion of homicides that are unsolved; save the output of prop.test as an R object, apply the broom::tidy to this object and pull the estimated proportion and confidence intervals from the resulting tidy dataframe.
```{r}
Baltimore_data = total_counts %>%
  filter(city_state == "Baltimore, MD")

prop.test(n = pull(Baltimore_data, totnumber_homicide), 
          x = pull(Baltimore_data, totnumber_unsolved)) %>%
  broom::tidy() %>%
  select(estimate, conf.low, conf.high)
```

Now run prop.test for each of the cities in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each. Do this within a â€œtidyâ€ pipeline, making use of purrr::map, purrr::map2, list columns and unnest as necessary to create a tidy dataframe with estimated proportions and CIs for each city.
```{r}
# Run prop.test and create a tidy dataframe with estimated proportions and CIs for each city
# Filter out rows with zero or missing values for homicide counts
city_proportion_estimates = total_counts %>%
  filter(totnumber_homicide > 0 & totnumber_unsolved >= 0) %>%
  mutate(test_result = purrr::map2(totnumber_unsolved, totnumber_homicide, 
                                   ~ prop.test(.x, .y))) %>%
  mutate(test_result = purrr::map(test_result, broom::tidy)) %>%
  unnest(test_result) %>%
  select(city_state, estimate, conf.low, conf.high)

city_proportion_estimates
```


Create a plot that shows the estimates and CIs for each city â€“ check out geom_errorbar for a way to add error bars based on the upper and lower limits. Organize cities according to the proportion of unsolved homicides.

```{r}
# create a plot and add error bars
city_proportion_estimates %>%
  ggplot(aes (y=fct_reorder(city_state, estimate), x=estimate)) + 
  geom_bar(stat="identity", fill="pink") +
  geom_errorbar(aes(xmin=conf.low, xmax =conf.high)) +
  labs(x="Cities", y="Proportion of Unsolved Homicides")
```






